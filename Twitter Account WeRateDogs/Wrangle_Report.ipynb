{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog,it has over 4 million followers and has received international media coverage. In this project, we are going to wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What libraries I've used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas, numpy, requests, json, tweepy, seaborn, matplotlib.pyplot and %matplotlib inline to make plots show inside the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I gathered three different datasets from three different sources using three methods. \n",
    "1. The first one is WeRateDogs Twitter archive, this dataset is a file we can download from our class. I uploaded it to the same path with my notebook, then used pd.csv_read() to read it in the notebook.It contains basic tweet data for all 5000+ of their tweets, one column contains each tweet text, tweet_id, dog name, dog stages(pupper, poppo, doggo, floofer), rating numerator and rating denominator.\n",
    "2. The second dataset is image_predictions table. I downloaded it programmatically using the Requests library and its URL provided in the project instruction from Udacity's servers and saved it in image_predictions dataset. This table is full of image predictions (the top three only) alongside each tweet ID, image URL, and the image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images).\n",
    "3. The third dataset is df. I used the tweet IDs in the WeRateDogs Twitter archive, query the Twitter API for each tweet's JSON data using Python's Tweepy library and store each tweet's entire set of JSON data in a file called tweet_json.txt file. Written each tweet's JSON data to its own line. Then read this .txt file line by line into a pandas DataFrame df with tweet ID, retweet count, and favorite count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I used visual assessment and Programmatic assessment both. I used df.head() to display each piece of gathered data in the Jupyter Notebook and used df.info(), df.describe(), df.duplicated() to programmaticly assess the data at the same time.\n",
    "After assessing the datasets, I found several quality issues and 2 tidiness isuues  need to be fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fixed these problems one by one, and get the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used df.to_csv() function, I saved the cleaned data to a file: twitter_archive_master.csv at the same path with the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze and Visualize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I made a copy of the cleaned data to analyze. After analyzing and visualizing these datasets, I got three insights about the dog age and the rating; the dog breed and the the rating; the rating and the favorite counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I completed two reports about the projects: one document all my wrangle efforts done in this project; another is for sharing the the insights I got with others."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
